{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Scraping eBay Data Using Selenium\n",
    "\n",
    "This assignment will guide you through the steps required to scrape product data from [eBay](https://www.ebay.com/) using Selenium. Your goal is to collect data about products based on a specific search query and store the data in a CSV file for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Below is a step-by-step outline of the scraping process. Follow these steps and implement the required code to complete the assignment. Comment your code wherever necessary to explain your thought process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Set Up Selenium**\n",
    "1. Import the necessary modules from Selenium (e.g., `webdriver`, `By`, `Keys`, etc.).\n",
    "2. Set up the Chrome WebDriver to control the browser. Ensure you have downloaded the ChromeDriver executable and placed it in the correct directory.\n",
    "3. Navigate to the eBay homepage using the WebDriver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "service = Service(executable_path=\"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "page_url=\"https://www.ebay.com/\"\n",
    "driver.get(page_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Perform a Search**\n",
    "1. Identify the search bar element on the eBay homepage using an appropriate locator (e.g., `id`, `name`, `XPath`).\n",
    "2. Send a specific search query (e.g., \"laptops\") to the search bar and simulate pressing the Enter key.\n",
    "3. Wait for the search results page to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify the search bar element on the eBay homepage using an appropriate locator (e.g., `id`, `name`, `XPath`).\n",
    "# <input type=\"text\" class=\"gh-tb ui-autocomplete-input\" \n",
    "\n",
    "search_bar = driver.find_element(By.XPATH, \"//input[@class='gh-tb ui-autocomplete-input']\")\n",
    "\n",
    "# 2. Send a specific search query (e.g., \"laptops\") to the search bar and simulate pressing the Enter key.\n",
    "search_bar.send_keys(\"laptop\")\n",
    "\n",
    "# Press Enter to initiate the search\n",
    "search_bar.send_keys(Keys.ENTER)\n",
    "\n",
    "# Wait for the page to load\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3: Extract Product Data**\n",
    "1. Use `find_elements` to locate product titles, prices, and other relevant data on the search results page. For example:\n",
    "   - Product title: Locate elements displaying the product names.\n",
    "   - Price: Locate elements showing product prices.\n",
    "   - (Optional) Link: Extract the URL for each product.\n",
    "2. Loop through the extracted elements and store the data in a structured format (e.g., a Python list of dictionaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1572706651.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    # <!--F#f_0-->Windows 11 Dell Latitude Laptop Intel Core i5 6th Gen 8GB RAM 128GB SSD Warranty<!--F/--></span></div>\u001b[0m\n\u001b[1;37m                                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "no_pages=0\n",
    "\n",
    "while no_pages <=5:\n",
    "#    - Product title: Locate elements displaying the product names.\n",
    "# <div class=\"s-item__title\"><span role=\"heading\" aria-level=\"3\">\n",
    "    titles = driver.find_elements(By.XPATH, \"//div[@class='s-item__title']\")\n",
    "\n",
    "#    - Price: Locate elements showing product prices.\n",
    "# <div class=\"s-item__detail s-item__detail--primary\"><span class=\"s-item__price\">\n",
    "    prices = driver.find_elements(By.XPATH, \"//div[@class='s-item__detail s-item__detail--primary']\")\n",
    "\n",
    "#    - (Optional) Link: Extract the URL for each product.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4: Handle Pagination**\n",
    "1. Check for the presence of a \"Next\" button to navigate to the next page of results.\n",
    "2. Implement a loop to scrape multiple pages of search results. Break the loop when no more pages are available or after a set number of pages (e.g., 5 pages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5: Save Data to CSV**\n",
    "1. Use the `pandas` library to convert the scraped data into a DataFrame.\n",
    "2. Save the DataFrame to a CSV file with appropriate column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 6: Close the Browser**\n",
    "1. Once the scraping is complete, ensure the WebDriver is closed to release system resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deliverables**\n",
    "- Submit the Python script you implemented on your github, following the above steps.\n",
    "- Ensure that your script:\n",
    "  - Extracts data for at least 50 products.\n",
    "  - Includes product titles, prices, and links (if applicable).\n",
    "  - Saves the data to a CSV file named `ebay_products.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bonus Challenge**\n",
    "1. Add functionality to scrape product ratings and the number of reviews (if available).\n",
    "2. Include error handling to skip elements that might be missing data or inaccessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good luck!** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
